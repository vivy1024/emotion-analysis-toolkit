# 技术迭代路线

薛小川 · 西安工业大学 · 智能制造工程 2021 级
从零基础到 18,600 行工程化系统的完整技术成长记录。

---

## 阶段 0：Python 入门（2024.10）

| 日期 | 文件 | 内容 |
|------|------|------|
| 10.13 | `01.py` ~ `09转义符.py` | Python 基础语法：变量、数值、字符串、运算符 |
| 10.31 | `1.py` | 综合练习 |
| 11.07 | `形参实参.py` | 函数参数传递 |
| 12.18 | `qq.py` | 小工具脚本 |

**起点**: 一个机械专业学生，从 print("hello world") 开始。

---

## 阶段 1：FER2013 宏表情初探（2024.12.19 - 12.31）

| 日期 | 文件 | 内容 | 关键进展 |
|------|------|------|---------|
| 12.19 00:33 | `fer.py` | 第一个表情识别脚本 | 开始接触 CV |
| 12.19 01:00-01:20 | `fer2.py` ~ `fer8.py` | 连续 7 个版本迭代（凌晨1点还在写） | 快速试错 |
| 12.19 23:44-23:51 | `作业1.py` ~ `作业10.py` | 课程作业（白天上课晚上写毕设） | 双线并行 |
| 12.25 13:08 | `01fer.py` | MediaPipe 人脸关键点 + 手写 AU 规则 | 圣诞节在写代码 |
| 12.25 13:14-14:35 | `02fer.py` ~ `05fer.py` | 迭代 AU 映射和表情分类逻辑 | 4 小时 5 个版本 |
| 12.26 18:45 | `99.py` | 实验性代码 | |
| 12.28 14:43 | `06fer.py` | TensorFlow/Keras 加载预训练模型 | 首次用深度学习 |
| 12.28 15:19 | `07fer.py` | AU 检测 + 情绪分类组合 | |
| 12.29 18:23-23:58 | `07fer1.py` ~ `fer11.py` | FER 模型持续迭代 | |
| 12.30 00:53-01:38 | `fer12.py`, `fer13.py` | 凌晨继续优化 | |
| 12.31 10:29 | `yuchuli.py` | 数据预处理脚本（拼音命名） | |
| 12.31 11:01 | `main.py` | 第一个完整的主程序 | |

**特征**: 文件名从拼音（yuchuli）到英文（fer），代码从 145 行到 12,000 行。凌晨编码是常态。

---

## 阶段 2：模型训练与打包（2025.01.01 - 01.08）

| 日期 | 文件 | 内容 | 关键进展 |
|------|------|------|---------|
| 01.01 00:07 | `fer_app.py` | 表情识别应用封装 | 新年第一天在写代码 |
| 01.01 01:05 | `XUNLIAN.py` | 训练脚本（拼音命名） | 自己训练模型 |
| 01.01 01:44 | `python build.py` | PyInstaller 打包 | 尝试做成可执行文件 |
| 01.06 23:12 | `shooting_game.py` | 表情控制射击游戏 | 探索应用场景 |
| 01.08 08:38 | `0.py` | 实验代码 | |

**特征**: 开始有产品化思维（打包、应用场景探索）。

---

## 阶段 3：FER2013 深入训练（2025.03.08 - 03.13）

| 日期 | 文件 | 内容 | 关键进展 |
|------|------|------|---------|
| 03.08 02:16 | `fer13.py` | FER2013 重新训练 | 凌晨 2 点 |
| 03.08 02:25-02:43 | `fer14.py` ~ `fer16.py` | 连续迭代 3 个版本 | |
| 03.09 22:17 | `模型微表情识别.py` | 用训练好的模型做推理 | 首次中文命名 |
| 03.13 05:22 | `fer17.py` | 最终版 FER 训练 | |

**特征**: 间隔 2 个月后回来，说明中间在做其他课程或准备。

---

## 阶段 4：架构设计大爆发（2025.03.25 - 04.14）

这是技术能力飞跃最大的阶段，20 天内从脚本式代码进化到工程化架构。

### 第一周：基础架构搭建（03.25 - 03.28）

| 日期 | 内容 | 关键进展 |
|------|------|---------|
| 03.25 | 光流计算、批处理、可视化工具 | 开始做视频级特征提取 |
| 03.25 | 数据加载器、AU 检测器、运动分析 | 模块化设计萌芽 |
| 03.26 | 表情分类器、FACS 解析器、面部分析器 | 引入 FACS 理论 |
| 03.26 | 光流增强（时序策略 + 空间策略） | 数据增强体系 |
| 03.27 | AU 解析器、表情映射器、模型集成器 | |
| 03.28 | 数据平衡模块（class_weight、SMOTE） | 开始处理类别不平衡 |
| 03.28 | 基础数据加载器、配置管理器、可视化器 | |

### 第二周：平衡与增强（03.29 - 04.05）

| 日期 | 内容 | 关键进展 |
|------|------|---------|
| 03.29 | 视频级数据平衡 | |
| 04.03 | FER2013 新训练脚本 | |
| 04.03-04.04 | 模型训练器、数据加载器、主程序 | 训练流程成型 |
| 04.05 | `balancing/` 完整重构：core/strategies/utils 三层架构 | 首次真正的模块化设计 |
| 04.05 | 注意力机制模块 | |

### 第三周：模型架构探索（04.06 - 04.12）

| 日期 | 内容 | 关键进展 |
|------|------|---------|
| 04.06 | 训练可视化器 | |
| 04.07 | 插件系统、应用入口、训练运行器 | 架构越来越复杂 |
| 04.08 | 大量基础设施：错误处理、内存管理、早停、性能监控、资源监控 | 工程化意识觉醒 |
| 04.08 | 数据集类（MicroExpressionDataset、MixupDataset） | |
| 04.08 | 特征空间增强、Mixup 增强 | |
| 04.09 | 配置系统、预处理流水线、模型工厂 | |
| 04.09 | **advanced_models.py** — Transformer 架构（8头注意力） | 首次尝试 Transformer |
| 04.09 | **hybrid_models.py** — 3D-CNN + LSTM 混合架构 | |
| 04.09 | 训练器、统一增强器、管道接口 | |
| 04.11 | **cnn_lstm_models.py** — CNN-LSTM 模型 | |
| 04.11 | **cnn_models.py** — 纯 CNN 模型 | |
| 04.11 | **lstm_models.py** — 纯 LSTM 模型 | |
| 04.11 | `train_model.py` — 881 行完整训练脚本 | |
| 04.12 04:11 | `train.py` — 训练入口 | 凌晨 4 点 |
| 04.12 13:21 | **dmca_net.py** — DMCANet 双流多通道注意力网络（815行） | 最复杂的模型 |
| 04.12 13:25 | `bench_dmca_net.py` — 性能基准测试 | |
| 04.12 19:08 | 模型工厂更新、数据集信息工具 | |
| 04.12 23:57 | **dmca_net_plus.py** — DMCANet 精简版 | |

### 第四周：DMCANet 增强与显存困境（04.13 - 04.14）

| 日期 | 内容 | 关键进展 |
|------|------|---------|
| 04.13 01:45 | 特征提取器重构 | |
| 04.13 02:05-02:50 | 预处理流水线、后台运行、OpenFace 集成 | |
| 04.13 03:00-04:30 | MediaPipe 特征增强、统一增强器、数据增强 | |
| 04.13 04:30 | **train_dmca_net.py** — DMCANet 训练脚本 | |
| 04.13 04:30 | **fix_train_dmca_net.py** — 修复训练问题 | 显存不够开始出问题 |
| 04.13 06:06 | **memory_efficient_split.py** — 内存高效数据分割 | 试图解决显存问题 |
| 04.13 15:32 | 修复缩进问题 | |
| 04.13 20:34 | **train_dmca_net_new.py** — 新版训练脚本 | 继续尝试 |
| 04.13 20:36 | **dmca_net_enhanced_backup.py** — 增强版备份 | |
| 04.13 20:39 | **prepare_input_format.py** — 输入格式准备 | |
| 04.14 16:05 | **dmca_net_enhanced.py** — DMCANet 增强版（1028行） | 最终版本 |
| 04.14 22:01 | 修复缩进 | |

**转折点**: 04.13-04.14 两天密集尝试训练 DMCANet，但 8GB 显存始终不够。`memory_efficient_split.py`、`fix_train_dmca_net.py` 这些文件名记录了挣扎的过程。最终不得不放弃复杂模型。

---

## 阶段 5：退回轻量方案 + PyTorch 重写（2025.04.16 - 05.05）

| 日期 | 内容 | 关键进展 |
|------|------|---------|
| 04.16 | `feature_extractor.py` — 特征提取器 | 回到基础 |
| 04.28 | `macro_models.py` — 宏表情模型 | |
| 04.29 | `main_pytorch.py` — PyTorch 主训练脚本 | 从 TF 转向 PyTorch |
| 05.03 | `fer17main_pytorch.py`（1178行）— 完整 PyTorch 训练 | |
| 05.03 | 数据增强器、数据平衡器、动态阈值 | |
| 05.03 | `fer18.py`、微表情集成模块 | |
| 05.05 | `casme_processor.py` — CASME II 数据处理器 | 正式开始微表情 |

**特征**: 放弃了复杂模型，转向 PyTorch，专注于能在 8GB 显存上跑的方案。

---

## 阶段 6：CNN-LSTM 两阶段成型（2025.05.10 - 06.11）

| 日期 | 内容 | 关键进展 |
|------|------|---------|
| 05.10 | 测试和工具模块整理 | |
| 05.11 | AU 情绪引擎 | |
| 05.12 | 实时处理器 | |
| 05.14 | AU 可视化工具 | |
| 05.16 | SVR 回归器 | |
| 05.21-05.27 | 论文撰写辅助脚本（参考文献重编号、章节生成） | 边写代码边写论文 |
| 06.01 | 杂项整理 | |
| 06.05 | 论文各章节生成脚本 | |
| 06.11 05:16 | **18_2/ 全部文件** — CNN-LSTM 两阶段最终版 | 凌晨 5 点完成 |
| 06.11 05:16 | `train_cnn.py`、`train_lstm.py`、`extract_features.py` | |
| 06.11 05:16 | `models.py`（CNNModel + LSTMOnlyModel） | |
| 06.11 05:16 | `hpo_train.py` — Optuna 超参搜索 | |
| 06.11 05:16 | `enhance_hidden/` — 完整实时检测系统 | |

**特征**: 06.11 凌晨 5 点一次性提交了所有核心代码，说明是通宵完成的。

---

## 阶段 7：系统集成与最终版（2025.06.12）

| 日期 | 内容 | 关键进展 |
|------|------|---------|
| 06.12 03:27 | `main.py`、`micro_emotion_panel.py` 最终更新 | 凌晨 3 点 |
| 06.12 03:35-03:38 | 所有引擎文件最终版 | |
| 06.12 | `hidden_emotion_detection/` 完整系统 | 18,600 行 |

---

## 阶段 8：宏表情模型优化（2025.07.04）

| 日期 | 内容 | 关键进展 |
|------|------|---------|
| 07.04 | `multi_dataset_train.py` — 多数据集训练 | 毕设答辩后继续优化 |

---

## 统计总结

### 时间投入

- **总跨度**: 2024.10.13 — 2025.07.04（约 9 个月）
- **核心开发期**: 2024.12.19 — 2025.06.12（约 6 个月）
- **凌晨编码次数**: 至少 15 次（00:00-06:00 有文件修改记录）
- **通宵记录**: 04.12（凌晨4点）、06.11（凌晨5点）、06.12（凌晨3点）

### 代码量演变

| 阶段 | 代码量 | 文件数 |
|------|--------|--------|
| 阶段 1（FER 初探） | ~12,000 行 | 8 个 |
| 阶段 4（架构爆发） | ~5,000 行模型 + ~10,000 行基础设施 | 100+ 个 |
| 阶段 5（PyTorch 重写） | ~3,400 行 | 11 个 |
| 阶段 7（最终系统） | 18,600 行 | 61 个 |

### 技术栈演变

```
MediaPipe 手写规则 → TensorFlow/Keras → PyTorch
单文件脚本 → 模块化设计 → 事件驱动架构
拼音命名(yuchuli) → 英文命名 → 规范化工程结构
FER2013 → CASME II → CNN-LSTM 两阶段
简单 CNN → DMCANet/Transformer（显存不够）→ 轻量 CNN-LSTM
```

### 被迫放弃的模型

| 模型 | 代码行数 | 放弃原因 |
|------|---------|---------|
| DMCANet | 815 行 | 8GB 显存不够 |
| DMCANetEnhanced | 1,028 行 | 8GB 显存不够 |
| Transformer | 242 行 | 8GB 显存不够 |
| 3D-CNN+LSTM Hybrid | 505 行 | 8GB 显存不够 |
| **合计** | **2,590 行** | **全部因硬件限制放弃** |
