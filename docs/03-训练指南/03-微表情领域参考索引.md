# 微表情领域参考索引

> 来源: [awesome-micro-expression-recognition](https://github.com/Vision-Intelligence-and-Robots-Group/awesome-micro-expression-recognition)
> 整理时间: 2026-02-18

---

## 一、与本项目直接相关的模型

按与隐藏情绪检测系统的相关度排序。

### 1. MMST — 宏表情增强微表情识别（★★★ 必读）

- **论文**: Micro-Expression Recognition Enhanced by Macro-Expression from Spatial-Temporal Domain
- **会议**: IJCAI 2021
- **核心思路**: 用宏表情信息增强微表情识别，空间-时间域联合建模
- **与本项目关系**: 和我们的隐藏情绪检测（宏微冲突分析）思路高度一致。我们检测宏微不一致来判断隐藏情绪，MMST 则用宏表情辅助微表情识别。可以互相借鉴。

### 2. MMNet — 肌肉运动引导网络（★★★）

- **论文**: MMNet: Muscle motion-guided network for micro-expression recognition
- **会议**: IJCAI 2022
- **核心思路**: 基于面部肌肉运动模式引导特征学习
- **与本项目关系**: 和我们的 AU 检测引擎思路相通。AU 本质就是面部肌肉动作单元，MMNet 的肌肉运动建模可以增强 AU 检测精度。

### 3. AU-GACN — AU 辅助图注意力网络（★★★）

- **论文**: AU-assisted graph attention convolutional network for micro-expression recognition
- **会议**: ACM MM 2020
- **核心思路**: 用 AU 信息构建面部图结构，图注意力卷积做识别
- **与本项目关系**: 直接对应我们的 AU+情绪融合方案。可以替代当前的 SVM AU 检测器。

### 4. Micron-BERT — BERT 微表情识别（★★☆）

- **论文**: Micron-BERT: BERT-Based Facial Micro-Expression Recognition
- **会议**: CVPR 2023
- **核心思路**: 将 BERT 的 masked modeling 思想应用到微表情视频帧
- **与本项目关系**: 当前 SOTA 级别方法。如果有足够算力（>12GB VRAM），值得尝试。

### 5. MOL — 联合估计框架（★★☆）

- **论文**: MOL: Joint Estimation of Micro-Expression, Optical Flow, and Landmark via Transformer-Graph-Style Convolution
- **期刊**: TPAMI 2025
- **核心思路**: Transformer + 图卷积联合估计微表情、光流和关键点
- **与本项目关系**: 最新方法，将多个子任务统一建模。和我们多引擎并行的架构思路不同但可以借鉴。

### 6. Feature Representation + Transformer Fusion（★★☆）

- **论文**: Feature Representation Learning with Adaptive Displacement Generation and Transformer Fusion for Micro-Expression Recognition
- **会议**: CVPR 2023
- **核心思路**: 自适应位移生成 + Transformer 融合
- **与本项目关系**: 和 archived_models 中的 Transformer 方案方向一致，可作为升级参考。

### 7. Short-Long Range Spatio-Temporal Transformer（★★☆）

- **论文**: Short and Long Range Relation Based Spatio-Temporal Transformer for Micro-Expression Recognition
- **期刊**: TAFFC 2022
- **核心思路**: 短程+长程时空关系建模
- **与本项目关系**: 和 archived_models/advanced_models.py 中的 Transformer 方案方向一致。

---

## 二、关键警告论文

### Data Leakage and Evaluation Issues（⚠️ 必读）

- **论文**: Data Leakage and Evaluation Issues in Micro-Expression Analysis
- **期刊**: TAC 2024
- **核心内容**: 指出微表情领域常见的数据泄漏和评估问题
- **对我们的影响**: 当前使用训练集内 5-fold 交叉验证，可能存在数据泄漏风险。标准做法应该是 LOSO（Leave-One-Subject-Out），确保同一受试者的样本不同时出现在训练集和测试集中。

---

## 三、跨数据集评估参考

| 论文 | 会议/期刊 | 说明 |
|------|-----------|------|
| Cross-Database Micro-Expression Recognition: A Benchmark | TKDE 2021 | 跨数据集基准，标准化评估协议 |
| Cross-database Micro-Expression Recognition with Deep CNN | TKDE 2021 | 深度 CNN 跨数据集方法 |
| Dual-Inception Network for Cross-database MER | FG 2019 | 双 Inception 跨数据集网络 |

---

## 四、MEGC 挑战赛分析

> 参赛代码已克隆到 `references/megc/` 目录

### MEGC2025（ACM MM 2025）

两个赛道：

**ME-STR（Spot-then-Recognize）**:

| 名次 | 方案 | 团队 | 核心方法 |
|------|------|------|---------|
| 1st | Prior-Guided Video-Level Regression | 北京科技大学 | 先验引导的视频级回归 |
| 2nd | FGSL | 中科大 | 频率门控时空学习 |
| 3rd | Spatiotemporal Multimodal LLM | 长治学院/太原师范 | 多模态大模型 |

**ME-VQA（视觉问答，新任务）**:

| 名次 | 方案 | 团队 | 核心方法 |
|------|------|------|---------|
| 1st | Emotion-Qwen-VL | 联想数科/西南大学 | Qwen-VL 全量微调 |
| 2nd | HierMEQA | 中科大 | 层次化关系感知框架 |
| 3rd | Temporal Info Enhanced VLM | 中科院合肥/北航 | 时序增强视觉语言模型 |

### MEGC2024（ACM MM 2024）— 代码已下载

**CCS（Cross-Cultural Spotting）**:

| 名次 | 方案 | 代码 | 核心方法 |
|------|------|------|---------|
| 1st | 光流+边界校准（中科大） | `megc2024-ccs-1st/` | 18通道ROI光流 + 两阶段边界校准，纯传统方法 |
| 2nd | 多尺度特征+光流校正（中科大） | `megc_spotting_code/` | VideoMAE-v2 特征 + ActionFormer + 光流后处理 |

**STR（Spot-then-Recognize）**:

| 名次 | 方案 | 代码 | 核心方法 |
|------|------|------|---------|
| 1st | VideoMAE V2 + 时序适配器（中科大） | `MEGC2024-STR/` | ViT-G 冻结 + 轻量适配器微调 + FPN 多尺度检测 |
| 2nd | 数据不平衡处理（哈工大） | `MEGC2024-CODE/` | 18-ROI光流 + Transformer + 加权交叉熵[1,3,9,9] |

### 评估指标

- **STRS** = Spotting F1 × Recognition F1（代码: `STRS-Metric/`）
- Spotting: IoU ≥ 0.5 判定为 TP，贪心匹配
- Recognition: 仅对 TP 样本评估情绪分类，UF1 + UAR
- 情绪类别: negative / positive / surprise（3类）

### 关键技术发现

1. **CCS 冠军用纯传统方法**（光流+阈值）击败了深度学习方案，说明微表情 spotting 中光流特征仍然非常有效
2. **STR 冠军的核心创新**是时序适配器——在冻结的 VideoMAE V2 ViT-G 中插入轻量 1D 深度卷积，仅训练 2-3% 参数
3. **数据不平衡**是关键问题，亚军用 [1,3,9,9] 类别权重直接处理
4. **中科大几乎包揽所有名次**，是该领域绝对强队
5. **VQA 赛道**代表前沿方向，用多模态大模型（Qwen-VL）做微表情问答

---

## 五、经典方法演进路线

```
传统特征 (2013-2016)
  LBP-TOP → STLBP-IP → MDMO → 光流特征
      ↓
浅层网络 (2017-2019)
  DSSN → STSTNet → CapsuleNet → SRCN
      ↓
图网络 + 注意力 (2020-2021)
  AU-GACN → MER-GCN → Graph-TCN → GACN → MMNet
      ↓
Transformer 时代 (2022-2023)
  Spatio-Temporal Transformer → Micron-BERT → ADG+Transformer
      ↓
多模态/大模型 (2024-2025)
  MOL (TPAMI 2025) → MELLM (LLM-powered) → MEGC2025 VQA
```

### 我们的位置

当前方案（CNN-LSTM 两阶段）处于浅层网络到图网络之间的过渡阶段。archived_models 中的 DMCANet/Transformer 尝试对应图网络+注意力阶段，因显存限制未能训练。

### 升级路线建议

1. **短期**: 申请更多数据集 + 实现 LOSO 评估 + 参考 STRS-Metric 评估脚本
2. **中期**: 参考 MEGC2024 CCS 冠军的光流 spotting 方案改进实时检测；实现 MMNet 或 AU-GACN
3. **长期**: 参考 MEGC2024 STR 冠军的 VideoMAE V2 + 适配器方案；探索 VQA 赛道的多模态大模型方向

---

## 六、重要综述论文

| 论文 | 年份 | 说明 |
|------|------|------|
| Video-based Facial Micro-Expression Analysis: A Survey | TPAMI 2021 | 最全面的综述 |
| Facial Micro-Expressions: An Overview | Proc. IEEE 2023 | IEEE 旗舰期刊综述 |
| Deep Learning for Micro-expression Recognition: A Survey | arXiv 2021 | 深度学习方法综述 |
| An overview of facial micro-expression analysis | TAFFC 2022 | 数据+方法+挑战 |

---

## 七、学习资源

- **CSIG 系列讲座**: https://space.bilibili.com/668807963/video （中文）
- **赵国英教授讲座**: https://www.bilibili.com/video/BV1zR4y1M7dw （智能情感感知）
- **韩虎/洪晓鹏讲座**: https://www.bilibili.com/video/BV1KQ4y1N7JS （超越人脸识别）
