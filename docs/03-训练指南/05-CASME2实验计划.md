# CASME II 评估实验计划 (Experiment Spec)

> 基线: ROI Transformer, UF1=0.4712, UAR=0.4991, 251样本/26被试/4类 LOSO
> 约束: 仅使用现有 CASME II 数据，无需新数据集

---

## 实验1: SVM/MLP Baseline 对比（优先级: 高）

**目的**: 验证 ROI 光流特征本身的质量。如果 SVM 也能到 0.4+，说明特征好、Transformer 的时序建模贡献有限；如果 SVM 只有 0.2，说明 Transformer 的序列建模是关键。

**方案**:
- 从 (T, 14) 序列中提取统计特征: 每个 ROI 通道的 mean/std/max/min/range → 14×5 = 70 维
- 分类器: SVM-RBF, SVM-Linear, MLP, RandomForest
- 评估: 同样的 LOSO 协议, UF1/UAR

**改动**: 新增 `train_baselines.py`，复用现有 features_casme2/ 的 npy 文件
**预计耗时**: 代码 + 运行 < 30分钟（无需 GPU）

---

## 实验2: max_seq_len 消融（优先级: 高）

**目的**: 微表情持续时间短（CASME II 200fps 下通常 10-50 帧），当前 max_seq_len=64 可能包含过多无关帧。

**方案**:
| max_seq_len | 说明 |
|-------------|------|
| 16 | 仅保留核心微表情帧 |
| 32 | 中等截断 |
| 64 | 当前默认 |
| 128 | 保留更多上下文 |

**改动**: 无代码改动，仅改命令行参数 `--max_seq_len`
**预计耗时**: 4 次训练，每次约 10 分钟

---

## 实验3: Transformer 超参数消融（优先级: 中）

**目的**: 当前模型可能过大或过小，找到最优配置。

**方案**:
| 实验 | 变量 | 值 |
|------|------|-----|
| 3a | depth | 1, 2, **3**, 4 |
| 3b | dim | 32, **64**, 128 |
| 3c | lr | 0.0001, **0.001**, 0.01 |
| 3d | dropout | **0.1**, 0.2, 0.3 |

加粗为当前默认值。每组只变一个参数，其余保持默认。

**改动**: 无代码改动
**预计耗时**: 约 12 次训练

---

## 实验4: 数据增强（优先级: 中）

**目的**: 251 样本太少，通过数据增强扩充训练集。

**方案**:
- 时间翻转 (temporal flip): 将序列倒序，标签不变
- 高斯噪声: 对光流特征加 N(0, 0.01) 噪声
- 随机时间裁剪: 随机截取 70%-100% 的子序列

**改动**: 修改 `CASME2ROIDataset.__getitem__` 添加 augmentation 参数
**预计耗时**: 代码改动 + 1 次训练

---

## 实验5: 类别策略消融（优先级: 中）

**目的**: 4 类中 others(97) 和 negative(97) 占 77%，类别极度不平衡。

**方案**:
| 策略 | 类别数 | 说明 |
|------|--------|------|
| 当前 | 4 | others/positive/surprise/negative |
| 3类 | 3 | 去掉 others，只分 pos/sur/neg |
| 二分类 | 2 | others vs non-others |

**改动**: 修改标签映射逻辑
**预计耗时**: 3 次训练

---

## 实验6: 特征增强（优先级: 低）

**目的**: 当前每帧只有 (dx, dy)×7=14 维，信息可能不够。

**方案**:
- 加入光流幅值: magnitude = sqrt(dx²+dy²) → 每帧 7×3=21 维
- 加入帧间差分: Δflow = flow[t] - flow[t-1] → 捕捉加速度
- 需要重新提取特征（修改 extract_roi_features.py）

**改动**: 修改特征提取 + 模型输入维度
**预计耗时**: 特征重提取 ~20小时 + 训练

---

## 执行顺序建议

```
实验1 (SVM baseline)     ← 最快出结果，论文必需
  ↓
实验2 (max_seq_len)      ← 零代码改动，直接跑
  ↓
实验5 (类别策略)          ← 小改动，验证问题定义
  ↓
实验3 (超参数)            ← 系统性调参
  ↓
实验4 (数据增强)          ← 需要改 Dataset
  ↓
实验6 (特征增强)          ← 需要重新提取，最后做
```

## 当前数据分布参考

```
类别分布: others=97, negative=97, positive=32, surprise=25
情绪分布: others=97, disgust=61, happiness=32, repression=27, surprise=25, sadness=7, fear=2
序列长度: min=23, max=140, mean=66, median=60, p25=50, p75=85
```

---

## 实验结果汇总（2026-02-28）

### 实验1: 分类器对比

| 分类器 | UF1 | UAR | 说明 |
|--------|-----|-----|------|
| SVM-RBF | 0.2199 | 0.2278 | 70维统计特征 |
| SVM-Linear | 0.2211 | 0.2304 | 70维统计特征 |
| MLP | 0.1860 | 0.2139 | 70维统计特征 |
| RandomForest | 0.1693 | 0.1933 | 70维统计特征 |
| **Transformer** | **0.4712** | **0.4991** | **(T,14) 序列特征** |

结论: Transformer 的时序建模是关键，统计特征丢失时序信息后性能接近随机。

### 实验2: max_seq_len 消融

| max_seq_len | UF1 | UAR |
|-------------|-----|-----|
| 16 | 0.4283 | 0.4449 |
| 32 | 0.4344 | 0.4455 |
| **64** | **0.4712** | **0.4991** |
| 128 | 0.4306 | 0.4311 |

结论: 64 最优。太短丢失上下文，太长引入噪声。

### 实验3: 超参数消融

**depth** (默认=3):

| depth | UF1 | UAR |
|-------|-----|-----|
| 1 | 0.4245 | 0.4244 |
| 2 | 0.3995 | 0.4006 |
| **3** | **0.4712** | **0.4991** |
| 4 | 0.4837 | 0.4892 |

**dim** (默认=64):

| dim | UF1 | UAR |
|-----|-----|-----|
| 32 | 0.5097 | 0.4952 |
| **64** | **0.4712** | **0.4991** |
| 128 | 0.4508 | 0.4472 |

**lr** (默认=0.001):

| lr | UF1 | UAR |
|----|-----|-----|
| 0.0001 | 0.3141 | 0.3273 |
| **0.001** | **0.4712** | **0.4991** |
| 0.01 | 0.4848 | 0.4855 |

**dropout** (默认=0.1):

| dropout | UF1 | UAR |
|---------|-----|-----|
| 0.1 | 0.4712 | 0.4991 |
| 0.2 | 0.4176 | 0.4289 |
| **0.3** | **0.5150** | **0.5250** |

**组合测试**:

| 配置 | UF1 | UAR |
|------|-----|-----|
| dim=32 + dropout=0.3 | 0.4492 | 0.4450 |
| dropout=0.3 (正式) | 0.4885 | 0.4877 |

结论: dropout=0.3 单独效果最好（UF1=0.5150），但存在随机波动。dim=32 和 depth=4 也有提升趋势。

### 最优配置

```
dropout=0.3, dim=64, depth=3, max_seq_len=64, lr=0.001
UF1 ≈ 0.49-0.52, UAR ≈ 0.49-0.53 (存在随机波动)
```

### 关键发现

1. **时序建模是核心**: Transformer (0.47-0.52) >> SVM/MLP (0.17-0.22)
2. **正则化很重要**: dropout=0.3 比 0.1 提升约 10%，小数据集需要更强正则化
3. **模型不宜过大**: dim=32 优于 128，depth=4 略优于 3
4. **序列长度 64 最优**: 与 CASME II 200fps 下微表情持续时间匹配
5. **超参数有交互效应**: 单独最优的参数组合后不一定更好

### 实验4: 数据增强

| 配置 | UF1 | UAR |
|------|-----|-----|
| 无增强 (dropout=0.3) | 0.4432 | 0.4443 |
| 时间翻转+噪声 | 0.4632 | 0.4468 |

混淆矩阵（无增强 → 有增强）:

```
              others  positive  surprise  negative
others       69→54      5→3      6→2     17→38
positive      5→12      7→6      5→0     15→14
surprise      9→7       2→1      7→7      7→10
negative     22→15      8→5     12→3     55→74
```

结论:
- 增强对 negative 召回率提升明显 (57%→76%)，但 others 精度下降
- positive (32样本) 和 surprise (25样本) 始终很差 (~20-28%)，根本原因是样本不足
- 整体 UF1 小幅提升 (+0.02)，增强有一定效果但不显著
